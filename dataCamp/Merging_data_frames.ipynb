{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging DataFrames with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading multiple data files\n",
    "\n",
    "### Tools for pandas data import\n",
    "\n",
    "* pd.read_csv() for CSV files\n",
    "    * dataframe = pd.read_csv(filepath)\n",
    "    * dozens of optional input parameters\n",
    "* Other data import tools:\n",
    "    * pd.read_excel()\n",
    "    * pd.read_html()\n",
    "    * pd.read_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading separate files\n",
    "dataframe0 = pd.read_csv('data/Sales/sales-jan-2015.csv')\n",
    "dataframe1 = pd.read_csv('data/Sales/sales-feb-2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using for loops\n",
    "filenames = ['data/Sales/sales-jan-2015.csv', 'data/Sales/sales-feb-2015.csv']\n",
    "dataframes = []\n",
    "for f in filenames:\n",
    "    dataframes.append(pd.read_csv(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a list comprehension\n",
    "dataframes = [pd.read_csv(f) for f in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using glob\n",
    "filenames = glob('data/Sales/sales*.csv')\n",
    "dataframes = [pd.read_csv(f) for f in filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading DataFrames from multiple files\n",
    "\n",
    "When data is spread among several files, you usually invoke pandas' read_csv() (or a similar data import function) multiple times to load the data into several DataFrames.\n",
    "\n",
    "The data files for this example have been derived from a list of Olympic medals awarded between 1896 & 2008 compiled by the [Guardian](https://www.theguardian.com/sport/datablog/2012/jun/25/olympic-medal-winner-list-data).\n",
    "\n",
    "The column labels of each DataFrame are NOC, Country, & Total where NOC is a three-letter code for the name of the country and Total is the number of medals of that type won (bronze, silver, or gold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country   Total\n",
      "0  USA   United States  2088.0\n",
      "1  URS    Soviet Union   838.0\n",
      "2  GBR  United Kingdom   498.0\n",
      "3  FRA          France   378.0\n",
      "4  GER         Germany   407.0\n"
     ]
    }
   ],
   "source": [
    "# Read 'Bronze.csv' into a DataFrame: bronze\n",
    "bronze = pd.read_csv('data/summer_Olympic_medals/Bronze.csv')\n",
    "\n",
    "# Read 'Silver.csv' into a DataFrame: silver\n",
    "silver = pd.read_csv('data/summer_Olympic_medals/Silver.csv')\n",
    "\n",
    "# Read 'Gold.csv' into a DataFrame: gold\n",
    "gold = pd.read_csv('data/summer_Olympic_medals/Gold.csv')\n",
    "\n",
    "# Print the first five rows of gold\n",
    "print(gold.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading DataFrames from multiple files in a loop\n",
    "\n",
    "Notice that this approach is not restricted to working with CSV files. That is, even if your data comes in other formats, as long as pandas has a suitable data import function, you can apply a loop or comprehension to generate a list of DataFrames imported from the source files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country   Total\n",
      "0  USA   United States  2088.0\n",
      "1  URS    Soviet Union   838.0\n",
      "2  GBR  United Kingdom   498.0\n",
      "3  FRA          France   378.0\n",
      "4  GER         Germany   407.0\n"
     ]
    }
   ],
   "source": [
    "# Create the list of file names: filenames\n",
    "filenames = ['data/summer_Olympic_medals/Gold.csv', 'data/summer_Olympic_medals/Silver.csv', 'data/summer_Olympic_medals/Bronze.csv']\n",
    "\n",
    "# Create the list of three DataFrames: dataframes\n",
    "dataframes = []\n",
    "for filename in filenames:\n",
    "    dataframes.append(pd.read_csv(filename))\n",
    "\n",
    "# Print top 5 rows of 1st DataFrame in dataframes\n",
    "print(dataframes[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining DataFrames from multiple data files\n",
    "\n",
    "In this exercise, you'll combine the three DataFrames from earlier exercises - gold, silver, & bronze - into a single DataFrame called medals. The approach you'll use here is clumsy. Later on in the course, you'll see various powerful methods that are frequently used in practice for concatenating or merging DataFrames.\n",
    "\n",
    "Remember, the column labels of each DataFrame are NOC, Country, and Total, where NOC is a three-letter code for the name of the country and Total is the number of medals of that type won."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country    Gold  Silver  Bronze\n",
      "0  USA   United States  2088.0  1195.0  1052.0\n",
      "1  URS    Soviet Union   838.0   627.0   584.0\n",
      "2  GBR  United Kingdom   498.0   591.0   505.0\n",
      "3  FRA          France   378.0   461.0   475.0\n",
      "4  GER         Germany   407.0   350.0   454.0\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of gold: medals\n",
    "medals = gold.copy()\n",
    "\n",
    "# Create list of new column labels: new_labels\n",
    "new_labels = ['NOC', 'Country', 'Gold']\n",
    "\n",
    "# Rename the columns of medals using new_labels\n",
    "medals.columns = new_labels\n",
    "\n",
    "# Add columns 'Silver' & 'Bronze' to medals\n",
    "medals['Silver'] = silver['Total']\n",
    "medals['Bronze'] = bronze['Total']\n",
    "\n",
    "# Print the head of medals\n",
    "print(medals.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindexing DataFrames\n",
    "\n",
    "**“Indexes” vs. “Indices”**\n",
    "* indices: many index labels within Index data structures (entries)\n",
    "* indexes: many pandas Index data structures (fisrt column)\n",
    "\n",
    "```python\n",
    "# Importing weather data\n",
    "import pandas as pd \n",
    "w_mean = pd.read_csv('quarterly_mean_temp.csv', index_col='Month')\n",
    "w_max = pd.read_csv('quarterly_max_temp.csv', index_col='Month')\n",
    "\n",
    "# Examining the data\n",
    "In [4]: print(w_mean)\n",
    "Month Mean TemperatureF\n",
    "Apr 61.956044\n",
    "Jan 32.133333\n",
    "Jul 68.934783\n",
    "Oct 43.434783\n",
    "In [5]: print(w_max)\n",
    "Month Mean TemperatureF\n",
    "Jan 68\n",
    "Apr 89\n",
    "Jul 91\n",
    "Oct 84\n",
    "\n",
    "# DataFrame indexes\n",
    "In [6]: print(w_mean.index)\n",
    "Index(['Apr', 'Jan', 'Jul', 'Oct'], dtype='object', name='Month')\n",
    "In [7]: print(w_max.index)\n",
    "Index(['Jan', 'Apr', 'Jul', 'Oct'], dtype='object', name='Month')\n",
    "In [8]: print(type(w_mean.index))\n",
    "<class 'pandas.indexes.base.Index'>\n",
    "\n",
    "# Using .reindex()\n",
    "In [9]: ordered = ['Jan', 'Apr', 'Jul', 'Oct']\n",
    "In [10]: w_mean2 = w_mean.reindex(ordered)\n",
    "In [11]: print(w_mean2)\n",
    "Month Mean TemperatureF\n",
    "Jan 32.133333\n",
    "Apr 61.956044\n",
    "Jul 68.934783\n",
    "Oct 43.434783\n",
    "\n",
    "# Using .sort_index()\n",
    "In [12]: w_mean2.sort_index()\n",
    "Out[12]:\n",
    "Month Mean TemperatureF\n",
    "Apr 61.956044\n",
    "Jan 32.133333\n",
    "Jul 68.934783\n",
    "Oct 43.434783\n",
    "\n",
    "# Reindex from a DataFrame Index\n",
    "In [13]: w_mean.reindex(w_max.index)\n",
    "Out[13]:\n",
    "Month Mean TemperatureF\n",
    "Jan 32.133333\n",
    "Apr 61.956044\n",
    "Jul 68.934783\n",
    "Oct 43.434783\n",
    "\n",
    "# Reindexing with missing labels\n",
    "In [14]: w_mean3 = w_mean.reindex(['Jan', 'Apr', 'Dec'])\n",
    "In [15]: print(w_mean3)\n",
    "Month Mean TemperatureF\n",
    "Jan 32.133333\n",
    "Apr 61.956044\n",
    "Dec NaN\n",
    "\n",
    "# Reindex from a DataFrame Index\n",
    "In [16]: w_max.reindex(w_mean3.index)\n",
    "Out[16]:\n",
    " Max TemperatureF\n",
    "Month\n",
    "Jan 68.0\n",
    "Apr 89.0\n",
    "Dec NaN\n",
    "In [17]: w_max.reindex(w_mean3.index).dropna()\n",
    "Out[17]:\n",
    " Max TemperatureF\n",
    "Month\n",
    "Jan 68.0\n",
    "Apr 89.0\n",
    "\n",
    "# ORDER MATTERS\n",
    "In [18]: w_max.reindex(w_mean.index)\n",
    "Out[18]:\n",
    " Max TemperatureF\n",
    "Month\n",
    "Apr 89\n",
    "Jan 68\n",
    "Jul 91\n",
    "Oct 84\n",
    "In [19]: w_mean.reindex(w_max.index)\n",
    "Out[19]:\n",
    " Mean TemperatureF\n",
    "Month\n",
    "Jan 32.133333\n",
    "Apr 61.956044\n",
    "Jul 68.934783\n",
    "Oct 43.434783\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting DataFrame with the Index & columns\n",
    "\n",
    "It is often useful to rearrange the sequence of the rows of a DataFrame by sorting. You don't have to implement these yourself; the principal methods for doing this are .sort_index() and .sort_values().\n",
    "\n",
    "In this exercise, you'll use these methods with a DataFrame of temperature values indexed by month names. You'll sort the rows alphabetically using the Index and numerically using a column. Notice, for this data, the original ordering is probably most useful and intuitive: the purpose here is for you to understand what the sorting methods do.\n",
    "\n",
    "```python\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read 'monthly_max_temp.csv' into a DataFrame: weather1\n",
    "weather1 = pd.read_csv('monthly_max_temp.csv', index_col='Month')\n",
    "\n",
    "# Print the head of weather1\n",
    "print(weather1.head())\n",
    "\n",
    "# Sort the index of weather1 in alphabetical order: weather2\n",
    "weather2 = weather1.sort_index()\n",
    "\n",
    "# Print the head of weather2\n",
    "print(weather2.head())\n",
    "\n",
    "# Sort the index of weather1 in reverse alphabetical order: weather3\n",
    "weather3 = weather1.sort_index(ascending=False)\n",
    "\n",
    "# Print the head of weather3\n",
    "print(weather3.head())\n",
    "\n",
    "# Sort weather1 numerically using the values of 'Max TemperatureF': weather4\n",
    "weather4 = weather1.sort_values('Max TemperatureF')\n",
    "\n",
    "# Print the head of weather4\n",
    "print(weather4.head())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindexing DataFrame from a list\n",
    "\n",
    "Sorting methods are not the only way to change DataFrame Indexes. There is also the .reindex() method.\n",
    "\n",
    "In this exercise, you'll reindex a DataFrame of quarterly-sampled mean temperature values to contain monthly samples (this is an example of upsampling or increasing the rate of samples, which you may recall from the pandas Foundations course).\n",
    "\n",
    "The original data has the first month's abbreviation of the quarter (three-month interval) on the Index, namely Apr, Jan, Jul, and Sep. This data has been loaded into a DataFrame called weather1 and has been printed in its entirety in the IPython Shell. Notice it has only four rows (corresponding to the first month of each quarter) and that the rows are not sorted chronologically.\n",
    "\n",
    "You'll initially use a list of all twelve month abbreviations and subsequently apply the .ffill() method to forward-fill the null entries when upsampling. This list of month abbreviations has been pre-loaded as year.\n",
    "\n",
    "```python\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Reindex weather1 using the list year: weather2\n",
    "weather2 = weather1.reindex(year)\n",
    "\n",
    "# Print weather2\n",
    "print(weather2)\n",
    "\n",
    "# Reindex weather1 using the list year with forward-fill: weather3\n",
    "weather3 = weather1.reindex(year).ffill()\n",
    "\n",
    "# Print weather3\n",
    "print(weather3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindexing using another DataFrame Index\n",
    "\n",
    "Another common technique is to reindex a DataFrame using the Index of another DataFrame. The DataFrame .reindex() method can accept the Index of a DataFrame or Series as input. You can access the Index of a DataFrame with its .index attribute.\n",
    "\n",
    "The Baby Names Dataset from data.gov summarizes counts of names (with genders) from births registered in the US since 1881. In this exercise, you will start with two baby-names DataFrames names_1981 and names_1881 loaded for you.\n",
    "\n",
    "The DataFrames names_1981 and names_1881 both have a MultiIndex with levels name and gender giving unique labels to counts in each row. If you're interested in seeing how the MultiIndexes were set up, names_1981 and names_1881 were read in using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_1981 = pd.read_csv('data/baby_names/names1981.csv', header=None, names=['name','gender','count'], index_col=(0,1))\n",
    "names_1881 = pd.read_csv('data/baby_names/names1881.csv', header=None, names=['name','gender','count'], index_col=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1935, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_1881.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19455, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_1981.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see by looking at their shapes the DataFrame corresponding to 1981 births is much larger, reflecting the greater diversity of names in 1981 as compared to 1881.\n",
    "\n",
    "Your job here is to use the DataFrame .reindex() and .dropna() methods to make a DataFrame common_names counting names from 1881 that were still popular in 1981."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1935, 1)\n",
      "(1587, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reindex names_1981 with index of names_1881: common_names\n",
    "common_names = names_1981.reindex(names_1881.index)\n",
    "\n",
    "# Print shape of common_names\n",
    "print(common_names.shape)\n",
    "\n",
    "# Drop rows with null counts: common_names\n",
    "common_names = common_names.dropna()\n",
    "\n",
    "# Print shape of new common_names\n",
    "print(common_names.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic with Series & DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2013-07-01    0.18\n",
       "2013-07-02    0.14\n",
       "2013-07-03    0.00\n",
       "2013-07-04    0.25\n",
       "2013-07-05    0.02\n",
       "2013-07-06    0.06\n",
       "2013-07-07    0.10\n",
       "Name: PrecipitationIn, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading weather data\n",
    "weather = pd.read_csv('data/pittsburgh2013.csv', index_col='Date', parse_dates=True)\n",
    "weather.loc['2013-7-1':'2013-7-7', 'PrecipitationIn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2013-07-01    0.4572\n",
       "2013-07-02    0.3556\n",
       "2013-07-03    0.0000\n",
       "2013-07-04    0.6350\n",
       "2013-07-05    0.0508\n",
       "2013-07-06    0.1524\n",
       "2013-07-07    0.2540\n",
       "Name: PrecipitationIn, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar multiplication\n",
    "weather.loc['2013-07-01':'2013-07-07', 'PrecipitationIn'] * 2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Min TemperatureF  Max TemperatureF\n",
      "Date                                          \n",
      "2013-07-01                66                79\n",
      "2013-07-02                66                84\n",
      "2013-07-03                71                86\n",
      "2013-07-04                70                86\n",
      "2013-07-05                69                86\n",
      "2013-07-06                70                89\n",
      "2013-07-07                70                77\n"
     ]
    }
   ],
   "source": [
    "# Absolute temperature range\n",
    "week1_range = weather.loc['2013-07-01':'2013-07-07',['Min TemperatureF', 'Max TemperatureF']]\n",
    "print(week1_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2013-07-01    72\n",
      "2013-07-02    74\n",
      "2013-07-03    78\n",
      "2013-07-04    77\n",
      "2013-07-05    76\n",
      "2013-07-06    78\n",
      "2013-07-07    72\n",
      "Name: Mean TemperatureF, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Average temperature\n",
    "week1_mean = weather.loc['2013-07-01':'2013-07-07', 'Mean TemperatureF']\n",
    "print(week1_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esousa/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py:3772: RuntimeWarning: Cannot compare type 'Timestamp' with type 'str', sort order is undefined for incomparable objects\n",
      "  return this.join(other, how=how, return_indexers=return_indexers)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2013-07-01 00:00:00</th>\n",
       "      <th>2013-07-02 00:00:00</th>\n",
       "      <th>2013-07-03 00:00:00</th>\n",
       "      <th>2013-07-04 00:00:00</th>\n",
       "      <th>2013-07-05 00:00:00</th>\n",
       "      <th>2013-07-06 00:00:00</th>\n",
       "      <th>2013-07-07 00:00:00</th>\n",
       "      <th>Min TemperatureF</th>\n",
       "      <th>Max TemperatureF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            2013-07-01 00:00:00  2013-07-02 00:00:00  2013-07-03 00:00:00  \\\n",
       "Date                                                                        \n",
       "2013-07-01                  NaN                  NaN                  NaN   \n",
       "2013-07-02                  NaN                  NaN                  NaN   \n",
       "2013-07-03                  NaN                  NaN                  NaN   \n",
       "2013-07-04                  NaN                  NaN                  NaN   \n",
       "2013-07-05                  NaN                  NaN                  NaN   \n",
       "2013-07-06                  NaN                  NaN                  NaN   \n",
       "2013-07-07                  NaN                  NaN                  NaN   \n",
       "\n",
       "            2013-07-04 00:00:00  2013-07-05 00:00:00  2013-07-06 00:00:00  \\\n",
       "Date                                                                        \n",
       "2013-07-01                  NaN                  NaN                  NaN   \n",
       "2013-07-02                  NaN                  NaN                  NaN   \n",
       "2013-07-03                  NaN                  NaN                  NaN   \n",
       "2013-07-04                  NaN                  NaN                  NaN   \n",
       "2013-07-05                  NaN                  NaN                  NaN   \n",
       "2013-07-06                  NaN                  NaN                  NaN   \n",
       "2013-07-07                  NaN                  NaN                  NaN   \n",
       "\n",
       "            2013-07-07 00:00:00  Min TemperatureF  Max TemperatureF  \n",
       "Date                                                                 \n",
       "2013-07-01                  NaN               NaN               NaN  \n",
       "2013-07-02                  NaN               NaN               NaN  \n",
       "2013-07-03                  NaN               NaN               NaN  \n",
       "2013-07-04                  NaN               NaN               NaN  \n",
       "2013-07-05                  NaN               NaN               NaN  \n",
       "2013-07-06                  NaN               NaN               NaN  \n",
       "2013-07-07                  NaN               NaN               NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relative temperature range\n",
    "week1_range / week1_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Min TemperatureF</th>\n",
       "      <th>Max TemperatureF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.097222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-02</th>\n",
       "      <td>0.891892</td>\n",
       "      <td>1.135135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-03</th>\n",
       "      <td>0.910256</td>\n",
       "      <td>1.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-04</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.116883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-05</th>\n",
       "      <td>0.907895</td>\n",
       "      <td>1.131579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-06</th>\n",
       "      <td>0.897436</td>\n",
       "      <td>1.141026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-07</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>1.069444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Min TemperatureF  Max TemperatureF\n",
       "Date                                          \n",
       "2013-07-01          0.916667          1.097222\n",
       "2013-07-02          0.891892          1.135135\n",
       "2013-07-03          0.910256          1.102564\n",
       "2013-07-04          0.909091          1.116883\n",
       "2013-07-05          0.907895          1.131579\n",
       "2013-07-06          0.897436          1.141026\n",
       "2013-07-07          0.972222          1.069444"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week1_range.divide(week1_mean, axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2013-07-01         NaN\n",
       "2013-07-02    2.777778\n",
       "2013-07-03    5.405405\n",
       "2013-07-04   -1.282051\n",
       "2013-07-05   -1.298701\n",
       "2013-07-06    2.631579\n",
       "2013-07-07   -7.692308\n",
       "Name: Mean TemperatureF, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage changes\n",
    "week1_mean.pct_change() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Total\n",
      "Country               \n",
      "United States   1052.0\n",
      "Soviet Union     584.0\n",
      "United Kingdom   505.0\n",
      "France           475.0\n",
      "Germany          454.0\n"
     ]
    }
   ],
   "source": [
    "# Bronze Olympic medals\n",
    "bronze = pd.read_csv('data/summer_Olympic_medals/bronze_top5.csv', index_col=0)\n",
    "print(bronze) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Total\n",
      "Country               \n",
      "United States   1195.0\n",
      "Soviet Union     627.0\n",
      "United Kingdom   591.0\n",
      "France           461.0\n",
      "Italy            394.0\n"
     ]
    }
   ],
   "source": [
    "# Silver Olympic medals\n",
    "silver = pd.read_csv('data/summer_Olympic_medals/silver_top5.csv', index_col=0)\n",
    "print(silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Total\n",
      "Country               \n",
      "United States   2088.0\n",
      "Soviet Union     838.0\n",
      "United Kingdom   498.0\n",
      "Italy            460.0\n",
      "Germany          407.0\n"
     ]
    }
   ],
   "source": [
    "# Gold Olympic medals\n",
    "gold = pd.read_csv('data/summer_Olympic_medals/gold_top5.csv', index_col=0)\n",
    "print(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soviet Union</th>\n",
       "      <td>1211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>1096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>2247.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total\n",
       "Country               \n",
       "France           936.0\n",
       "Germany            NaN\n",
       "Italy              NaN\n",
       "Soviet Union    1211.0\n",
       "United Kingdom  1096.0\n",
       "United States   2247.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding bronze, silver\n",
    "bronze + silver # gives NaN in certain rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soviet Union</th>\n",
       "      <td>1211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>1096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>2247.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total\n",
       "Country               \n",
       "France           936.0\n",
       "Germany            NaN\n",
       "Italy              NaN\n",
       "Soviet Union    1211.0\n",
       "United Kingdom  1096.0\n",
       "United States   2247.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bronze.add(silver) # still gives NaN in certain rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soviet Union</th>\n",
       "      <td>1211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>1096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>2247.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total\n",
       "Country               \n",
       "France           936.0\n",
       "Germany          454.0\n",
       "Italy            394.0\n",
       "Soviet Union    1211.0\n",
       "United Kingdom  1096.0\n",
       "United States   2247.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using a fill_value\n",
    "bronze.add(silver, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soviet Union</th>\n",
       "      <td>2049.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>1594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>4335.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total\n",
       "Country               \n",
       "France           936.0\n",
       "Germany          861.0\n",
       "Italy            854.0\n",
       "Soviet Union    2049.0\n",
       "United Kingdom  1594.0\n",
       "United States   4335.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chaining .add()\n",
    "bronze.add(silver, fill_value=0).add(gold, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting in arithmetic formulas\n",
    "\n",
    "In this exercise, you'll work with weather data pulled from wunderground.com. The DataFrame weather has been pre-loaded along with pandas as pd. It has 365 rows (observed each day of the year 2013 in Pittsburgh, PA) and 22 columns reflecting different weather measurements each day.\n",
    "\n",
    "You'll subset a collection of columns related to temperature measurements in degrees Fahrenheit, convert them to degrees Celsius, and relabel the columns of the new DataFrame to reflect the change of units.\n",
    "\n",
    "Remember, ordinary arithmetic operators (like +, -, *, and /) broadcast scalar values to conforming DataFrames when combining scalars & DataFrames in arithmetic expressions. Broadcasting also works with pandas Series and NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Min TemperatureC  Mean TemperatureC  Max TemperatureC\n",
      "Date                                                             \n",
      "2013-01-01         -6.111111          -2.222222          0.000000\n",
      "2013-01-02         -8.333333          -6.111111         -3.888889\n",
      "2013-01-03         -8.888889          -4.444444          0.000000\n",
      "2013-01-04         -2.777778          -2.222222         -1.111111\n",
      "2013-01-05         -3.888889          -1.111111          1.111111\n"
     ]
    }
   ],
   "source": [
    "# Extract selected columns from weather as new DataFrame: temps_f\n",
    "temps_f = weather[['Min TemperatureF', 'Mean TemperatureF', 'Max TemperatureF']]\n",
    "\n",
    "# Convert temps_f to celsius: temps_c\n",
    "temps_c = (temps_f - 32) * 5/9\n",
    "\n",
    "# Rename 'F' in column names with 'C': temps_c.columns\n",
    "temps_c.columns = ['Min TemperatureC', 'Mean TemperatureC', 'Max TemperatureC']\n",
    "\n",
    "# Print first 5 rows of temps_c\n",
    "print(temps_c.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing percentage growth of GDP\n",
    "\n",
    "Your job in this exercise is to compute the yearly percent-change of US GDP (Gross Domestic Product) since 2008.\n",
    "\n",
    "The data has been obtained from the Federal Reserve Bank of St. Louis and is available in the file GDP.csv, which contains quarterly data; you will resample it to annual sampling and then compute the annual growth of GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              VALUE\n",
      "DATE               \n",
      "2014-07-01  17569.4\n",
      "2014-10-01  17692.2\n",
      "2015-01-01  17783.6\n",
      "2015-04-01  17998.3\n",
      "2015-07-01  18141.9\n",
      "2015-10-01  18222.8\n",
      "2016-01-01  18281.6\n",
      "2016-04-01  18436.5\n",
      "              VALUE\n",
      "DATE               \n",
      "2008-12-31  14549.9\n",
      "2009-12-31  14566.5\n",
      "2010-12-31  15230.2\n",
      "2011-12-31  15785.3\n",
      "2012-12-31  16297.3\n",
      "2013-12-31  16999.9\n",
      "2014-12-31  17692.2\n",
      "2015-12-31  18222.8\n",
      "2016-12-31  18436.5\n",
      "              VALUE    growth\n",
      "DATE                         \n",
      "2008-12-31  14549.9       NaN\n",
      "2009-12-31  14566.5  0.114090\n",
      "2010-12-31  15230.2  4.556345\n",
      "2011-12-31  15785.3  3.644732\n",
      "2012-12-31  16297.3  3.243524\n",
      "2013-12-31  16999.9  4.311144\n",
      "2014-12-31  17692.2  4.072377\n",
      "2015-12-31  18222.8  2.999062\n",
      "2016-12-31  18436.5  1.172707\n"
     ]
    }
   ],
   "source": [
    "# Read 'GDP.csv' into a DataFrame: gdp\n",
    "gdp = pd.read_csv('data/GDP/gdp_usa.csv', parse_dates=True, index_col='DATE')\n",
    "\n",
    "# Slice all the gdp data from 2008 onward: post2008\n",
    "post2008 = gdp.loc['2008-01-01':,:]\n",
    "\n",
    "# Print the last 8 rows of post2008\n",
    "print(post2008.tail(8))\n",
    "\n",
    "# Resample post2008 by year, keeping last(): yearly\n",
    "yearly = post2008.resample('A').last()\n",
    "\n",
    "# Print yearly\n",
    "print(yearly)\n",
    "\n",
    "# Compute percentage growth of yearly: yearly['growth']\n",
    "yearly['growth'] = yearly.pct_change() * 100\n",
    "\n",
    "# Print yearly again\n",
    "print(yearly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting currency of stocks\n",
    "\n",
    "In this exercise, stock prices in US Dollars for the S&P 500 in 2015 have been obtained from Yahoo Finance. The files sp500.csv for sp500 and exchange.csv for the exchange rates are both provided to you.\n",
    "\n",
    "Using the daily exchange rate to Pounds Sterling, your task is to convert both the Open and Close column prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open        Close\n",
      "Date                                \n",
      "2015-01-02  2058.899902  2058.199951\n",
      "2015-01-05  2054.439941  2020.579956\n",
      "2015-01-06  2022.150024  2002.609985\n",
      "2015-01-07  2005.550049  2025.900024\n",
      "2015-01-08  2030.609985  2062.139893\n",
      "                   Open        Close\n",
      "Date                                \n",
      "2015-01-02  1340.364425  1339.908750\n",
      "2015-01-05  1348.616555  1326.389506\n",
      "2015-01-06  1332.515980  1319.639876\n",
      "2015-01-07  1330.562125  1344.063112\n",
      "2015-01-08  1343.268811  1364.126161\n"
     ]
    }
   ],
   "source": [
    "# Read 'sp500.csv' into a DataFrame: sp500\n",
    "sp500 = pd.read_csv('data/sp500.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# Read 'exchange.csv' into a DataFrame: exchange\n",
    "exchange = pd.read_csv('data/exchange.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# Subset 'Open' & 'Close' columns from sp500: dollars\n",
    "dollars = sp500[['Open', 'Close']]\n",
    "\n",
    "# Print the head of dollars\n",
    "print(dollars.head())\n",
    "\n",
    "# Convert dollars to pounds: pounds\n",
    "pounds = dollars.multiply(exchange['GBP/USD'], axis='rows')\n",
    "\n",
    "# Print the head of pounds\n",
    "print(pounds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending & Concatenating Series\n",
    "\n",
    "**append()**\n",
    "* .append(): Series & DataFrame method\n",
    "* Invocation:\n",
    "    * s1.append(s2)\n",
    "* Stacks rows of s2 below s1\n",
    "* Method for Series & DataFrames\n",
    "\n",
    "**concat()**\n",
    "* concat(): pandas module function\n",
    "* Invocation:\n",
    "    * pd.concat([s1, s2, s3])\n",
    "* Can stack row-wise or column-wise\n",
    "\n",
    "**concat() & .append()**\n",
    "* Equivalence of concat() & .append():\n",
    "    * result1 = pd.concat([s1, s2, s3])\n",
    "    * result2 = s1.append(s2).append(s3)\n",
    "* result1 == result2 elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "northeast = pd.Series(['CT', 'ME', 'MA', 'NH', 'RI', 'VT', 'NJ', 'NY', 'PA'])\n",
    "south = pd.Series(['DE', 'FL', 'GA', 'MD', 'NC', 'SC', 'VA', 'DC', 'WV', 'AL', 'KY', 'MS', 'TN', 'AR', 'LA', 'OK', 'TX'])\n",
    "midwest = pd.Series(['IL', 'IN', 'MN', 'MO', 'NE', 'ND','SD', 'IA', 'KS', 'MI', 'OH', 'WI'])\n",
    "west = pd.Series(['AZ', 'CO', 'ID', 'MT', 'NV', 'NM','UT', 'WY', 'AK', 'CA', 'HI', 'OR','WA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     CT\n",
      "1     ME\n",
      "2     MA\n",
      "3     NH\n",
      "4     RI\n",
      "5     VT\n",
      "6     NJ\n",
      "7     NY\n",
      "8     PA\n",
      "0     DE\n",
      "1     FL\n",
      "2     GA\n",
      "3     MD\n",
      "4     NC\n",
      "5     SC\n",
      "6     VA\n",
      "7     DC\n",
      "8     WV\n",
      "9     AL\n",
      "10    KY\n",
      "11    MS\n",
      "12    TN\n",
      "13    AR\n",
      "14    LA\n",
      "15    OK\n",
      "16    TX\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Using .append()\n",
    "east = northeast.append(south)\n",
    "print(east) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  0,  1,  2,  3,  4,  5,  6,  7,\n",
      "             8,  9, 10, 11, 12, 13, 14, 15, 16],\n",
      "           dtype='int64')\n",
      "3    NH\n",
      "3    MD\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# The appended Index, problems!\n",
    "print(east.index)\n",
    "print(east.loc[3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     CT\n",
      "1     ME\n",
      "2     MA\n",
      "3     NH\n",
      "4     RI\n",
      "5     VT\n",
      "6     NJ\n",
      "7     NY\n",
      "8     PA\n",
      "9     DE\n",
      "10    FL\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Using .reset_index()\n",
    "new_east = northeast.append(south).reset_index(drop=True)\n",
    "print(new_east.head(11)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=26, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(new_east.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    CT\n",
      "1    ME\n",
      "2    MA\n",
      "3    NH\n",
      "4    RI\n",
      "5    VT\n",
      "6    NJ\n",
      "7    NY\n",
      "8    PA\n",
      "0    DE\n",
      "1    FL\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Using concat()\n",
    "east = pd.concat([northeast, south])\n",
    "print(east.head(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  0,  1,  2,  3,  4,  5,  6,  7,\n",
      "             8,  9, 10, 11, 12, 13, 14, 15, 16],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(east.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     CT\n",
      "1     ME\n",
      "2     MA\n",
      "3     NH\n",
      "4     RI\n",
      "5     VT\n",
      "6     NJ\n",
      "7     NY\n",
      "8     PA\n",
      "9     DE\n",
      "10    FL\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Using ignore_index\n",
    "new_east = pd.concat([northeast, south],ignore_index=True)\n",
    "print(new_east.head(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=26, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(new_east.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending pandas Series\n",
    "\n",
    "In this exercise, you'll load sales data from the months January, February, and March into DataFrames. Then, you'll extract Series with the 'Units' column from each and append them together with method chaining using .append().\n",
    "\n",
    "To check that the stacking worked, you'll print slices from these Series, and finally, you'll add the result to figure out the total units sold in the first quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-27 07:11:55    18\n",
      "2015-02-02 08:33:01     3\n",
      "2015-02-02 20:54:49     9\n",
      "Name: Units, dtype: int64\n",
      "Date\n",
      "2015-02-26 08:57:45     4\n",
      "2015-02-26 08:58:51     1\n",
      "2015-03-06 10:11:45    17\n",
      "2015-03-06 02:03:56    17\n",
      "Name: Units, dtype: int64\n",
      "642\n"
     ]
    }
   ],
   "source": [
    "# Load 'sales-jan-2015.csv' into a DataFrame: jan\n",
    "jan = pd.read_csv('data/Sales/sales-jan-2015.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# Load 'sales-feb-2015.csv' into a DataFrame: feb\n",
    "feb = pd.read_csv('data/Sales/sales-feb-2015.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# Load 'sales-mar-2015.csv' into a DataFrame: mar\n",
    "mar = pd.read_csv('data/Sales/sales-mar-2015.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# Extract the 'Units' column from jan: jan_units\n",
    "jan_units = jan['Units']\n",
    "\n",
    "# Extract the 'Units' column from feb: feb_units\n",
    "feb_units = feb['Units']\n",
    "\n",
    "# Extract the 'Units' column from mar: mar_units\n",
    "mar_units = mar['Units']\n",
    "\n",
    "# Append feb_units and then mar_units to jan_units: quarter1\n",
    "quarter1 = jan_units.append(feb_units).append(mar_units)\n",
    "\n",
    "# Print the first slice from quarter1\n",
    "print(quarter1.loc['jan 27, 2015':'feb 2, 2015'])\n",
    "\n",
    "# Print the second slice from quarter1\n",
    "print(quarter1.loc['feb 26, 2015':'mar 7, 2015'])\n",
    "\n",
    "# Compute & print total sales in quarter1\n",
    "print(quarter1.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating pandas Series along row axis\n",
    "\n",
    "Having learned how to append Series, you'll now learn how to achieve the same result by concatenating Series instead. You'll continue to work with the sales data you've seen previously. This time, the DataFrames jan, feb, and mar have been pre-loaded.\n",
    "\n",
    "Your job is to use pd.concat() with a list of Series to achieve the same result that you would get by chaining calls to .append().\n",
    "\n",
    "You may be wondering about the difference between pd.concat() and pandas' .append() method. One way to think of the difference is that .append() is a specific case of a concatenation, while pd.concat() gives you more flexibility, as you'll see in later exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-27 07:11:55    18\n",
      "2015-02-02 08:33:01     3\n",
      "2015-02-02 20:54:49     9\n",
      "Name: Units, dtype: int64\n",
      "Date\n",
      "2015-02-26 08:57:45     4\n",
      "2015-02-26 08:58:51     1\n",
      "2015-03-06 10:11:45    17\n",
      "2015-03-06 02:03:56    17\n",
      "Name: Units, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty list: units\n",
    "units = []\n",
    "\n",
    "# Build the list of Series\n",
    "for month in [jan, feb, mar]:\n",
    "    units.append(month['Units'])\n",
    "\n",
    "# Concatenate the list: quarter1\n",
    "quarter1 = pd.concat(units, axis='rows')\n",
    "\n",
    "# Print slices from quarter1\n",
    "print(quarter1.loc['jan 27, 2015':'feb 2, 2015'])\n",
    "print(quarter1.loc['feb 26, 2015':'mar 7, 2015'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending & concatenating DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "In [1]: import pandas as pd\n",
    "In [2]: pop1 = pd.read_csv('population_01.csv', index_col=0)\n",
    "In [3]: pop2 = pd.read_csv('population_02.csv', index_col=0)\n",
    "In [4]: print(type(pop1), pop1.shape)\n",
    "<class 'pandas.core.frame.DataFrame'> (4, 1)\n",
    "In [5]: print(type(pop2), pop2.shape)\n",
    "<class 'pandas.core.frame.DataFrame'> (4, 1)\n",
    "\n",
    "# Examining population data\n",
    "In [6]: print(pop1)\n",
    "      2010 Census Population\n",
    "Zip Code ZCTA\n",
    "66407 479\n",
    "72732 4716\n",
    "50579 2405\n",
    "46241 30670\n",
    "In [7]: print(pop2)\n",
    "      2010 Census Population\n",
    "Zip Code ZCTA\n",
    "12776 2180\n",
    "76092 26669\n",
    "98360 12221\n",
    "49464 27481\n",
    "\n",
    "# Appending population DataFrames\n",
    "In [8]: pop1.append(pop2)\n",
    "Out[8]:\n",
    "      2010 Census Population\n",
    "Zip Code ZCTA\n",
    "66407 479\n",
    "72732 4716\n",
    "50579 2405\n",
    "46241 30670\n",
    "12776 2180\n",
    "76092 26669\n",
    "98360 12221\n",
    "49464 27481\n",
    "In [9]: print(pop1.index.name, pop1.columns)\n",
    "Zip Code ZCTA Index(['2010 Census Population'], dtype='object')\n",
    "In [10]: print(pop2.index.name, pop2.columns)\n",
    "Zip Code ZCTA Index(['2010 Census Population'], dtype='object')\n",
    "\n",
    "# Population & unemployment data\n",
    "In [11]: population = pd.read_csv('population_00.csv', index_col=0)\n",
    "In [12]: unemployment = pd.read_csv('unemployment_00.csv', index_col=0)\n",
    "In [13]: print(population)\n",
    "      2010 Census Population\n",
    "Zip Code ZCTA\n",
    "57538 322\n",
    "59916 130\n",
    "37660 40038\n",
    "2860 45199\n",
    "In [14]: print(unemployment)\n",
    "     unemployment participants\n",
    "Zip\n",
    "2860 0.11 34447\n",
    "46167 0.02 4800\n",
    "1097 0.33 42\n",
    "80808 0.07 4310\n",
    "\n",
    "#Appending population & unemployment\n",
    "In [15]: population.append(unemployment)\n",
    "Out[15]:\n",
    " 2010 Census Population participants unemployment\n",
    "57538 322.0 NaN NaN\n",
    "59916 130.0 NaN NaN\n",
    "37660 40038.0 NaN NaN\n",
    "2860 45199.0 NaN NaN\n",
    "2860 NaN 34447.0 0.11\n",
    "46167 NaN 4800.0 0.02\n",
    "1097 NaN 42.0 0.33\n",
    "80808 NaN 4310.0 0.07\n",
    "\n",
    "# There is a lot of NaNs and a repeated index\n",
    "\n",
    "# Concatenating rows\n",
    "In [16]: pd.concat([population, unemployment], axis=0)\n",
    "Out[16]:\n",
    " 2010 Census Population participants unemployment\n",
    "57538 322.0 NaN NaN\n",
    "59916 130.0 NaN NaN\n",
    "37660 40038.0 NaN NaN\n",
    "2860 45199.0 NaN NaN\n",
    "2860 NaN 34447.0 0.11\n",
    "46167 NaN 4800.0 0.02\n",
    "1097 NaN 42.0 0.33\n",
    "80808 NaN 4310.0 0.07\n",
    "\n",
    "# Concatenating columns\n",
    "In [17]: pd.concat([population, unemployment], axis=1)\n",
    "Out[17]:\n",
    " 2010 Census Population unemployment participants\n",
    "1097 NaN 0.33 42.0\n",
    "2860 45199.0 0.11 34447.0\n",
    "37660 40038.0 NaN NaN\n",
    "46167 NaN 0.02 4800.0\n",
    "57538 322.0 NaN NaN\n",
    "59916 130.0 NaN NaN\n",
    "80808 NaN 0.07 4310.0\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
