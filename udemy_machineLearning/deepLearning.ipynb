{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8 - Deep Learning (DL)\n",
    "\n",
    "![Alt](./deeplearning.png \"Deep Learning\")\n",
    "\n",
    "### Neuron\n",
    "In DL a neuron is a node that processes the weighted inputs and passes the signal onto another neuron along the line.\n",
    "\n",
    "### Activation function\n",
    "* Threshold $ \\phi(x) = \\text{0 if x < 0, 1 otherwise} $\n",
    "\n",
    "* Sigmoid $ \\phi(x) = \\frac{1}{1+e^{-x}} $\n",
    "    - Smooth transition from 0 to 1\n",
    "    - good for predicting probabilities in the final/outpit layer\n",
    "    \n",
    "* Rectifier (Relu?) $ \\phi(x) = max(x,0) $\n",
    "    - _[Deep sparse rectifier neural networks](http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf) by Xavier Glorot et al. 2011_\n",
    "\n",
    "* Hyperbolic Tangent (tanh) $ \\phi(x) = \\frac{1-e^{-2x}}{1+e^{-2x}} $\n",
    "\n",
    "__Cost function__: $C = 0.5(\\hat{y}-y)^2$, function to be minimized\n",
    "\n",
    "[A list of cost functions used in neural network, alongside applications](http://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-network-alongside-applications) CrossValidated 2015\n",
    "\n",
    "### Gradient Descent\n",
    "* finding the right weights that give the minimum cost function requires a multi-demensional optimization problem\n",
    "* Convex cost function\n",
    "* Batch gradient descent, where all the samples are used for the calculation of the cost function the then all the weights are adjusted\n",
    "\n",
    "### Stochastic Gradient Descent\n",
    "* Useful for cases when the cost function has local minimums, in oder to find the __global minimum__.\n",
    "* The weights are adjust after each indivisual sample evaluation\n",
    "\n",
    "[A Neural Network in 13 lines of Python (part 2 - gradient descent)](https://iamtrask.github.io/2015/07/27/python-network-part2/)\n",
    "\n",
    "[Neural Network and Deep Learning by Michael Nielsen (2015)](http://neuralnetworksanddeeplearning.com/chap2.html)\n",
    "\n",
    "### Backpropagation\n",
    "* information propagates from output to input, allowing the update of all the weights simultanuously\n",
    "* allow us to see which part of the network is responsible for the most error\n",
    "\n",
    "## Artificial Neural Network (ANN) with Stochastic Gradient Descent\n",
    "\n",
    "__Step 1__: Randomly initialize the weights to small numbers close to 0, but not 0.\n",
    "\n",
    "__Step 2__: Input the first observation of you dataset in the input layer, each feature in one input node.\n",
    "\n",
    "__Step 3__: Forward-Propagation: from left to right, the neurons are activated in a way that the impact of each neuron's activation is limited by the weights. Propagate the activations until getting the predicted result y.\n",
    "\n",
    "__Step 4__: Compare the predicted result to tue actual result. Measure the generated error.\n",
    "\n",
    "__Step 5__: Back-Porpagation: from right to left, the error is back propagated. Update the weights according to how much they are responsible for the error. The learning rate decides by how much we update the weights.\n",
    "\n",
    "__Step 6__: Repeat steps 1-5 and update the weights after each observation (Reinforcement Learning). Or: Repeat steps 1-5 but update the weights only after a batch of observation (Batch Learning)\n",
    "\n",
    "__Step 7__: When the whole training set passed throught the ANN, that makes and epoch. Redo more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sousae/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the libraries that will be used\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "dir1 = '/home/sousae/Classes/udemy_machineLearning_A-Z/Part8_Deep_Learning/'\n",
    "dataset = pd.read_csv(dir1+'Churn_Modelling.csv')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([619, 'France', 'Female', 42, 2, 0.0, 1, 1, 1, 101348.88],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "\n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       6.1900000e+02, 4.2000000e+01, 2.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0134888e+05])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1,2])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]\n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.75486502, -0.57369368, -0.91601335,  0.91601335, -2.30455945,\n",
       "        0.30102557, -1.37744033, -0.00631193, -0.92159124,  0.64259497,\n",
       "        0.9687384 , -0.74866447])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sousae/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=12, units=6, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/home/sousae/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/home/sousae/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/sousae/anaconda3/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.5577 - acc: 0.7957\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.5082 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.5061 - acc: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 7s 927us/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.5058 - acc: 0.7960\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.5058 - acc: 0.7960\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.5057 - acc: 0.7960\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 6s 781us/step - loss: 0.5056 - acc: 0.7960\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.5054 - acc: 0.7960\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 8s 976us/step - loss: 0.5051 - acc: 0.7960\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 8s 952us/step - loss: 0.5046 - acc: 0.7960\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.5038 - acc: 0.7960\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 7s 817us/step - loss: 0.5024 - acc: 0.7960\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4998 - acc: 0.7960\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4952 - acc: 0.7960\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 8s 980us/step - loss: 0.4873 - acc: 0.7960\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.4754 - acc: 0.7960\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4606 - acc: 0.7960\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 11s 1ms/step - loss: 0.4447 - acc: 0.7960\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4302 - acc: 0.7960\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.4167 - acc: 0.7960\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 7s 899us/step - loss: 0.4062 - acc: 0.7960\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3981 - acc: 0.7960\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3916 - acc: 0.7960\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3867 - acc: 0.8029\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 8s 999us/step - loss: 0.3839 - acc: 0.8282\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3813 - acc: 0.8301\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 8s 965us/step - loss: 0.3796 - acc: 0.8344\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3777 - acc: 0.8357\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3770 - acc: 0.8389\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3753 - acc: 0.8370\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3749 - acc: 0.8394\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3731 - acc: 0.8412\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 8s 950us/step - loss: 0.3724 - acc: 0.8420\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 8s 974us/step - loss: 0.3720 - acc: 0.8409\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3702 - acc: 0.8407\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3700 - acc: 0.8437\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3689 - acc: 0.8440\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 8s 993us/step - loss: 0.3686 - acc: 0.8441\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3677 - acc: 0.8444\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3673 - acc: 0.8437\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3664 - acc: 0.8457\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3668 - acc: 0.8460\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3660 - acc: 0.8459\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3656 - acc: 0.8455\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3652 - acc: 0.8450\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3648 - acc: 0.8445\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 7s 891us/step - loss: 0.3647 - acc: 0.8446\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 7s 877us/step - loss: 0.3645 - acc: 0.8449\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 8s 954us/step - loss: 0.3633 - acc: 0.8470\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 8s 988us/step - loss: 0.3632 - acc: 0.8472\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3630 - acc: 0.8472\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3631 - acc: 0.8467\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 7s 870us/step - loss: 0.3614 - acc: 0.8469\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 8s 989us/step - loss: 0.3615 - acc: 0.8477\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3623 - acc: 0.8479\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3613 - acc: 0.8474\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3617 - acc: 0.8467\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3606 - acc: 0.8481\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3603 - acc: 0.8482\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3605 - acc: 0.8485\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3597 - acc: 0.8492\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3593 - acc: 0.8481\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 8s 950us/step - loss: 0.3593 - acc: 0.8501\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3586 - acc: 0.8496\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3580 - acc: 0.8496\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3583 - acc: 0.8487\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3574 - acc: 0.8510\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3572 - acc: 0.8525\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3570 - acc: 0.8509\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 8s 983us/step - loss: 0.3569 - acc: 0.8496\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3568 - acc: 0.8490\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3564 - acc: 0.8511\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3561 - acc: 0.8512\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3559 - acc: 0.8519\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 6s 809us/step - loss: 0.3552 - acc: 0.8509\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3551 - acc: 0.8512\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3549 - acc: 0.8502\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3543 - acc: 0.8516\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3534 - acc: 0.8537\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 7s 920us/step - loss: 0.3539 - acc: 0.8515\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 7s 872us/step - loss: 0.3534 - acc: 0.8532\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3533 - acc: 0.8541\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3529 - acc: 0.8526\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 7s 903us/step - loss: 0.3527 - acc: 0.8540\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3520 - acc: 0.8541\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 8s 971us/step - loss: 0.3513 - acc: 0.8535\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3510 - acc: 0.8551\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3505 - acc: 0.8537\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3497 - acc: 0.8545\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3497 - acc: 0.8566A: 0s - loss: 0.3474 -\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 7s 912us/step - loss: 0.3491 - acc: 0.8576\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 8s 1ms/step - loss: 0.3484 - acc: 0.8574\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 7s 903us/step - loss: 0.3478 - acc: 0.8560\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 10s 1ms/step - loss: 0.3479 - acc: 0.8560\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 9s 1ms/step - loss: 0.3479 - acc: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0331e92080>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 12))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1507   88]\n",
      " [ 185  220]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "__Step 1: Convolution__\n",
    "$$ (f*g)(t) = \\int_{-\\infty}^{\\infty} f(\\tau)g(t-\\tau) d\\tau $$\n",
    "\n",
    "[Introduction to Convolutional Neural Networks by Jianxin Wu](http://cs.nju.edu.cn/wujx/paper/CNN.pdf)\n",
    "\n",
    "[Understanding Convulutional Neural Networks with a Mathematical Model by C.C. Jay Kup 2016](https://arxiv.org/pdf/1609.04112.pdf)\n",
    "\n",
    "Input image + Feature Detector matrix (3x3) = Feature Map\n",
    "* The process will make the picture smaller.\n",
    "* Finds the features of the image while keep the spacial relations between\n",
    "\n",
    "There's multiple feature maps created using different filters/feature detector.\n",
    "\n",
    "__Step 1 (B) is a ReLU layer to beak up the linearity.__\n",
    "\n",
    "\n",
    "__Step 2: Max Pooling__\n",
    "* Used to address spacial variance (i.e. tild, stretch, distortion in an image)\n",
    "* Feature Map ---- Max pooling ----> Pooled Feature Map\n",
    "* Overlap with a matrix and selecting the maximun\n",
    "* Preserves the fearures\n",
    "* Reduces the size of the parameter space\n",
    "* Prevents overfitting by disregarding unnecessary information\n",
    "\n",
    "[Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition by Dominik Scherer et al. 2010](http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf)\n",
    "\n",
    "\n",
    "__Step 3: Flattening__\n",
    "* Pooled Feature Map ---- Flattening ----> vector to be the input to an ANN\n",
    "\n",
    "\n",
    "__Step 4: Full Connection__\n",
    "* Add an ANN to the previous steps\n",
    "\n",
    "[The 9 Deep learning papers You need to know about by Adit Deshpande 2016](https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html)\n",
    "\n",
    "#### Softmax and Cross-entropy\n",
    "* Softmax function $ f_j(z) = \\frac{e^{zj}}{\\sum_k e^{zk}} $\n",
    "* Makes sure the probabilities of the different classifications all add up to 1\n",
    "* Cross-Entropy function, used to calculate the error in the classification instead of MSE\n",
    "$$ L_i = \\log \\left(\\frac{e^{f_{yi}}}{\\sum_k e^{z_jk}} \\right) $$\n",
    "$$H(p,q) = -\\sum_x p(x) \\log q(x)$$\n",
    "\n",
    "[A Friendly Introduction to Cross-Entropy Loss by Rob DiPietro 2016](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 1 - Building the CNN\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2D in module keras.layers.convolutional:\n",
      "\n",
      "class Conv2D(_Conv)\n",
      " |  2D convolution layer (e.g. spatial convolution over images).\n",
      " |  \n",
      " |  This layer creates a convolution kernel that is convolved\n",
      " |  with the layer input to produce a tensor of\n",
      " |  outputs. If `use_bias` is True,\n",
      " |  a bias vector is created and added to the outputs. Finally, if\n",
      " |  `activation` is not `None`, it is applied to the outputs as well.\n",
      " |  \n",
      " |  When using this layer as the first layer in a model,\n",
      " |  provide the keyword argument `input_shape`\n",
      " |  (tuple of integers, does not include the sample axis),\n",
      " |  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
      " |  in `data_format=\"channels_last\"`.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      filters: Integer, the dimensionality of the output space\n",
      " |          (i.e. the number output of filters in the convolution).\n",
      " |      kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
      " |          width and height of the 2D convolution window.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |      strides: An integer or tuple/list of 2 integers,\n",
      " |          specifying the strides of the convolution along the width and height.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |          Specifying any stride value != 1 is incompatible with specifying\n",
      " |          any `dilation_rate` value != 1.\n",
      " |      padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |      data_format: A string,\n",
      " |          one of `channels_last` (default) or `channels_first`.\n",
      " |          The ordering of the dimensions in the inputs.\n",
      " |          `channels_last` corresponds to inputs with shape\n",
      " |          `(batch, height, width, channels)` while `channels_first`\n",
      " |          corresponds to inputs with shape\n",
      " |          `(batch, channels, height, width)`.\n",
      " |          It defaults to the `image_data_format` value found in your\n",
      " |          Keras config file at `~/.keras/keras.json`.\n",
      " |          If you never set it, then it will be \"channels_last\".\n",
      " |      dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
      " |          the dilation rate to use for dilated convolution.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |          Currently, specifying any `dilation_rate` value != 1 is\n",
      " |          incompatible with specifying any stride value != 1.\n",
      " |      activation: Activation function to use\n",
      " |          (see [activations](../activations.md)).\n",
      " |          If you don't specify anything, no activation is applied\n",
      " |          (ie. \"linear\" activation: `a(x) = x`).\n",
      " |      use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |      kernel_initializer: Initializer for the `kernel` weights matrix\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      bias_initializer: Initializer for the bias vector\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      kernel_regularizer: Regularizer function applied to\n",
      " |          the `kernel` weights matrix\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      bias_regularizer: Regularizer function applied to the bias vector\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      activity_regularizer: Regularizer function applied to\n",
      " |          the output of the layer (its \"activation\").\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      kernel_constraint: Constraint function applied to the kernel matrix\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |      bias_constraint: Constraint function applied to the bias vector\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |  \n",
      " |  # Input shape\n",
      " |      4D tensor with shape:\n",
      " |      `(samples, channels, rows, cols)` if data_format='channels_first'\n",
      " |      or 4D tensor with shape:\n",
      " |      `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
      " |  \n",
      " |  # Output shape\n",
      " |      4D tensor with shape:\n",
      " |      `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n",
      " |      or 4D tensor with shape:\n",
      " |      `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n",
      " |      `rows` and `cols` values might have changed due to padding.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2D\n",
      " |      _Conv\n",
      " |      keras.engine.topology.Layer\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(*args, **kwargs)\n",
      " |  \n",
      " |  get_config(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _Conv:\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(*args, **kwargs)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  from_config(cls, config) from __builtin__.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Container), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(64, 64, 3...)`\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=128, activation=\"relu\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"sigmoid\")`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation='relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(output_dim = 128, activation='relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:23: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=250, epochs=25, validation_steps=2000)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 198s 792ms/step - loss: 0.6759 - acc: 0.5635 - val_loss: 0.6048 - val_acc: 0.6708\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 149s 594ms/step - loss: 0.6099 - acc: 0.6703 - val_loss: 0.5849 - val_acc: 0.6852\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 148s 590ms/step - loss: 0.5549 - acc: 0.7170 - val_loss: 0.5350 - val_acc: 0.7403\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 147s 588ms/step - loss: 0.5259 - acc: 0.7318 - val_loss: 0.5327 - val_acc: 0.7313\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 148s 592ms/step - loss: 0.5066 - acc: 0.7483 - val_loss: 0.5023 - val_acc: 0.7509\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 149s 597ms/step - loss: 0.4898 - acc: 0.7598 - val_loss: 0.4910 - val_acc: 0.7660\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 148s 594ms/step - loss: 0.4798 - acc: 0.7671 - val_loss: 0.4824 - val_acc: 0.7700\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 150s 598ms/step - loss: 0.4682 - acc: 0.7788 - val_loss: 0.4577 - val_acc: 0.7879\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 149s 596ms/step - loss: 0.4516 - acc: 0.7869 - val_loss: 0.4591 - val_acc: 0.7825\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 150s 600ms/step - loss: 0.4421 - acc: 0.7881 - val_loss: 0.4861 - val_acc: 0.7635\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 149s 597ms/step - loss: 0.4332 - acc: 0.7999 - val_loss: 0.4810 - val_acc: 0.7676\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 150s 600ms/step - loss: 0.4187 - acc: 0.8067 - val_loss: 0.4653 - val_acc: 0.7905\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 149s 597ms/step - loss: 0.4012 - acc: 0.8184 - val_loss: 0.4615 - val_acc: 0.7937\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 151s 602ms/step - loss: 0.3999 - acc: 0.8140 - val_loss: 0.4561 - val_acc: 0.7954\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 150s 598ms/step - loss: 0.3844 - acc: 0.8300 - val_loss: 0.4493 - val_acc: 0.8010\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 151s 603ms/step - loss: 0.3741 - acc: 0.8301 - val_loss: 0.4499 - val_acc: 0.8030\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 150s 601ms/step - loss: 0.3639 - acc: 0.8415 - val_loss: 0.4500 - val_acc: 0.7959\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 150s 602ms/step - loss: 0.3591 - acc: 0.8384 - val_loss: 0.4506 - val_acc: 0.8032\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 151s 604ms/step - loss: 0.3501 - acc: 0.8424 - val_loss: 0.4428 - val_acc: 0.8037\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 151s 603ms/step - loss: 0.3328 - acc: 0.8505 - val_loss: 0.4382 - val_acc: 0.8101\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 153s 611ms/step - loss: 0.3223 - acc: 0.8572 - val_loss: 0.4482 - val_acc: 0.8049\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 151s 605ms/step - loss: 0.3147 - acc: 0.8613 - val_loss: 0.4753 - val_acc: 0.7917\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 151s 606ms/step - loss: 0.3062 - acc: 0.8644 - val_loss: 0.4625 - val_acc: 0.8116\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 157s 628ms/step - loss: 0.2945 - acc: 0.8710 - val_loss: 0.4677 - val_acc: 0.8093\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 152s 607ms/step - loss: 0.2934 - acc: 0.8761 - val_loss: 0.5190 - val_acc: 0.7801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef38746690>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('/disk1/sousae/Classes/udemy_machineLearning/Machine_Learning_A-Z/Part8_Deep_Learning/dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('/disk1/sousae/Classes/udemy_machineLearning/Machine_Learning_A-Z/Part8_Deep_Learning/dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 25,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
