{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8 - Deep Learning (DL)\n",
    "\n",
    "![Alt](./deeplearning.png \"Deep Learning\")\n",
    "\n",
    "### Neuron\n",
    "In DL a neuron is a node that processes the weighted inputs and passes the signal onto another neuron along the line.\n",
    "\n",
    "### Activation function\n",
    "* Threshold $ \\phi(x) = \\text{0 if x < 0, 1 otherwise} $\n",
    "\n",
    "* Sigmoid $ \\phi(x) = \\frac{1}{1+e^{-x}} $\n",
    "    - Smooth transition from 0 to 1\n",
    "    - good for predicting probabilities in the final/outpit layer\n",
    "    \n",
    "* Rectifier (Relu?) $ \\phi(x) = max(x,0) $\n",
    "    - _[Deep sparse rectifier neural networks](http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf) by Xavier Glorot et al. 2011_\n",
    "\n",
    "* Hyperbolic Tangent (tanh) $ \\phi(x) = \\frac{1-e^{-2x}}{1+e^{-2x}} $\n",
    "\n",
    "__Cost function__: $C = 0.5(\\hat{y}-y)^2$, function to be minimized\n",
    "\n",
    "[A list of cost functions used in neural network, alongside applications](http://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-network-alongside-applications) CrossValidated 2015\n",
    "\n",
    "### Gradient Descent\n",
    "* finding the right weights that give the minimum cost function requires a multi-demensional optimization problem\n",
    "* Convex cost function\n",
    "* Batch gradient descent, where all the samples are used for the calculation of the cost function the then all the weights are adjusted\n",
    "\n",
    "### Stochastic Gradient Descent\n",
    "* Useful for cases when the cost function has local minimums, in oder to find the __global minimum__.\n",
    "* The weights are adjust after each indivisual sample evaluation\n",
    "\n",
    "[A Neural Network in 13 lines of Python (part 2 - gradient descent)](https://iamtrask.github.io/2015/07/27/python-network-part2/)\n",
    "\n",
    "[Neural Network and Deep Learning by Michael Nielsen (2015)](http://neuralnetworksanddeeplearning.com/chap2.html)\n",
    "\n",
    "### Backpropagation\n",
    "* information propagates from output to input, allowing the update of all the weights simultanuously\n",
    "* allow us to see which part of the network is responsible for the most error\n",
    "\n",
    "## Artificial Neural Network (ANN) with Stochastic Gradient Descent\n",
    "\n",
    "__Step 1__: Randomly initialize the weights to small numbers close to 0, but not 0.\n",
    "\n",
    "__Step 2__: Input the first observation of you dataset in the input layer, each feature in one input node.\n",
    "\n",
    "__Step 3__: Forward-Propagation: from left to right, the neurons are activated in a way that the impact of each neuron's activation is limited by the weights. Propagate the activations until getting the predicted result y.\n",
    "\n",
    "__Step 4__: Compare the predicted result to tue actual result. Measure the generated error.\n",
    "\n",
    "__Step 5__: Back-Porpagation: from right to left, the error is back propagated. Update the weights according to how much they are responsible for the error. The learning rate decides by how much we update the weights.\n",
    "\n",
    "__Step 6__: Repeat steps 1-5 and update the weights after each observation (Reinforcement Learning). Or: Repeat steps 1-5 but update the weights only after a batch of observation (Batch Learning)\n",
    "\n",
    "__Step 7__: When the whole training set passed throught the ANN, that makes and epoch. Redo more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/esousa/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import the libraries that will be used\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "dir1 = '/Users/esousa/transfered/Classes/udemy_machineLearning_A-Z/Part8_Deep_Learning/'\n",
    "dataset = pd.read_csv(dir1+'Churn_Modelling.csv')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([619, 'France', 'Female', 42, 2, 0.0, 1, 1, 1, 101348.88],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values\n",
    "\n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esousa/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/esousa/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       6.1900000e+02, 4.2000000e+01, 2.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0134888e+05])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1,2])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]\n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.75486502, -0.57369368, -0.91601335,  0.91601335, -2.30455945,\n",
       "        0.30102557, -1.37744033, -0.00631193, -0.92159124,  0.64259497,\n",
       "        0.9687384 , -0.74866447])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esousa/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.5584 - acc: 0.7952\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.5085 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.5061 - acc: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.5060 - acc: 0.7960\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.5059 - acc: 0.7960\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.5058 - acc: 0.7960\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.5058 - acc: 0.7960\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.5058 - acc: 0.7960\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.5057 - acc: 0.7960\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.5056 - acc: 0.7960\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.5054 - acc: 0.7960\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.5049 - acc: 0.7960\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.5039 - acc: 0.7960\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.5013 - acc: 0.7960\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.4929 - acc: 0.7960\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.4694 - acc: 0.7970\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.4475 - acc: 0.8084\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.4387 - acc: 0.8095\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.4338 - acc: 0.8110\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.4285 - acc: 0.8117\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.4195 - acc: 0.8132\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.4072 - acc: 0.8207\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3950 - acc: 0.8294\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3836 - acc: 0.8360\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3743 - acc: 0.8434\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3685 - acc: 0.8470\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3637 - acc: 0.8501\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3597 - acc: 0.8506\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3568 - acc: 0.8546\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3542 - acc: 0.8562\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3521 - acc: 0.8556\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3506 - acc: 0.8581\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3496 - acc: 0.8591\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3482 - acc: 0.8590\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3474 - acc: 0.8567\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3466 - acc: 0.8564\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3458 - acc: 0.8592\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3458 - acc: 0.8584\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3447 - acc: 0.8577\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3434 - acc: 0.8586\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3433 - acc: 0.8599\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3422 - acc: 0.8596\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3430 - acc: 0.8607\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3411 - acc: 0.8600\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3417 - acc: 0.8584\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3411 - acc: 0.8601\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3407 - acc: 0.8584\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3407 - acc: 0.8584\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.3404 - acc: 0.8617\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3399 - acc: 0.8606\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3393 - acc: 0.8584\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3394 - acc: 0.8610\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3395 - acc: 0.8622\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3386 - acc: 0.8597\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3384 - acc: 0.8610\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3384 - acc: 0.8605\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3389 - acc: 0.8611\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3377 - acc: 0.8601\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3383 - acc: 0.8607\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3376 - acc: 0.8619\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3379 - acc: 0.8615\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3373 - acc: 0.8602\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3376 - acc: 0.8607\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3377 - acc: 0.8616\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3369 - acc: 0.8596\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3366 - acc: 0.8619\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3367 - acc: 0.8631\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3365 - acc: 0.8622\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3363 - acc: 0.8615\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3360 - acc: 0.8591\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3364 - acc: 0.8629\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3359 - acc: 0.8607\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3356 - acc: 0.8629\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3357 - acc: 0.8629\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3356 - acc: 0.8646\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3354 - acc: 0.8595\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3352 - acc: 0.8612\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3345 - acc: 0.8622\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3352 - acc: 0.8607\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3346 - acc: 0.8611\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3348 - acc: 0.8610\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3343 - acc: 0.8629\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3344 - acc: 0.8629\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3346 - acc: 0.8639\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3347 - acc: 0.8625\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3343 - acc: 0.8617\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3349 - acc: 0.8624\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3344 - acc: 0.8634\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3342 - acc: 0.8636\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3344 - acc: 0.8637\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3339 - acc: 0.8634\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3336 - acc: 0.8640\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3339 - acc: 0.8630\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.3338 - acc: 0.8611\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3340 - acc: 0.8639\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3340 - acc: 0.8606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2e869128>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", input_dim=12, units=6, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1521   74]\n",
      " [ 199  206]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "__Step 1: Convolution__\n",
    "$$ (f*g)(t) = \\int_{-\\infty}^{\\infty} f(\\tau)g(t-\\tau) d\\tau $$\n",
    "\n",
    "[Introduction to Convolutional Neural Networks by Jianxin Wu](http://cs.nju.edu.cn/wujx/paper/CNN.pdf)\n",
    "\n",
    "[Understanding Convulutional Neural Networks with a Mathematical Model by C.C. Jay Kup 2016](https://arxiv.org/pdf/1609.04112.pdf)\n",
    "\n",
    "Input image + Feature Detector matrix (3x3) = Feature Map\n",
    "* The process will make the picture smaller.\n",
    "* Finds the features of the image while keep the spacial relations between\n",
    "\n",
    "There's multiple feature maps created using different filters/feature detector.\n",
    "\n",
    "__Step 1 (B) is a ReLU layer to beak up the linearity.__\n",
    "\n",
    "\n",
    "__Step 2: Max Pooling__\n",
    "* Used to address spacial variance (i.e. tild, stretch, distortion in an image)\n",
    "* Feature Map ---- Max pooling ----> Pooled Feature Map\n",
    "* Overlap with a matrix and selecting the maximun\n",
    "* Preserves the fearures\n",
    "* Reduces the size of the parameter space\n",
    "* Prevents overfitting by disregarding unnecessary information\n",
    "\n",
    "[Evaluation of Pooling Operations in Convolutional Architectures for Object Recognition by Dominik Scherer et al. 2010](http://ais.uni-bonn.de/papers/icann2010_maxpool.pdf)\n",
    "\n",
    "\n",
    "__Step 3: Flattening__\n",
    "* Pooled Feature Map ---- Flattening ----> vector to be the input to an ANN\n",
    "\n",
    "\n",
    "__Step 4: Full Connection__\n",
    "* Add an ANN to the previous steps\n",
    "\n",
    "[The 9 Deep learning papers You need to know about by Adit Deshpande 2016](https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html)\n",
    "\n",
    "#### Softmax and Cross-entropy\n",
    "* Softmax function $ f_j(z) = \\frac{e^{zj}}{\\sum_k e^{zk}} $\n",
    "* Makes sure the probabilities of the different classifications all add up to 1\n",
    "* Cross-Entropy function, used to calculate the error in the classification instead of MSE\n",
    "$$ L_i = \\log \\left(\\frac{e^{f_{yi}}}{\\sum_k e^{z_jk}} \\right) $$\n",
    "$$H(p,q) = -\\sum_x p(x) \\log q(x)$$\n",
    "\n",
    "[A Friendly Introduction to Cross-Entropy Loss by Rob DiPietro 2016](https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Building the CNN\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2D in module keras.layers.convolutional:\n",
      "\n",
      "class Conv2D(_Conv)\n",
      " |  Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  2D convolution layer (e.g. spatial convolution over images).\n",
      " |  \n",
      " |  This layer creates a convolution kernel that is convolved\n",
      " |  with the layer input to produce a tensor of\n",
      " |  outputs. If `use_bias` is True,\n",
      " |  a bias vector is created and added to the outputs. Finally, if\n",
      " |  `activation` is not `None`, it is applied to the outputs as well.\n",
      " |  \n",
      " |  When using this layer as the first layer in a model,\n",
      " |  provide the keyword argument `input_shape`\n",
      " |  (tuple of integers, does not include the sample axis),\n",
      " |  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
      " |  in `data_format=\"channels_last\"`.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      filters: Integer, the dimensionality of the output space\n",
      " |          (i.e. the number of output filters in the convolution).\n",
      " |      kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
      " |          height and width of the 2D convolution window.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |      strides: An integer or tuple/list of 2 integers,\n",
      " |          specifying the strides of the convolution\n",
      " |          along the height and width.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |          Specifying any stride value != 1 is incompatible with specifying\n",
      " |          any `dilation_rate` value != 1.\n",
      " |      padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |          Note that `\"same\"` is slightly inconsistent across backends with\n",
      " |          `strides` != 1, as described\n",
      " |          [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n",
      " |      data_format: A string,\n",
      " |          one of `\"channels_last\"` or `\"channels_first\"`.\n",
      " |          The ordering of the dimensions in the inputs.\n",
      " |          `\"channels_last\"` corresponds to inputs with shape\n",
      " |          `(batch, height, width, channels)` while `\"channels_first\"`\n",
      " |          corresponds to inputs with shape\n",
      " |          `(batch, channels, height, width)`.\n",
      " |          It defaults to the `image_data_format` value found in your\n",
      " |          Keras config file at `~/.keras/keras.json`.\n",
      " |          If you never set it, then it will be \"channels_last\".\n",
      " |      dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
      " |          the dilation rate to use for dilated convolution.\n",
      " |          Can be a single integer to specify the same value for\n",
      " |          all spatial dimensions.\n",
      " |          Currently, specifying any `dilation_rate` value != 1 is\n",
      " |          incompatible with specifying any stride value != 1.\n",
      " |      activation: Activation function to use\n",
      " |          (see [activations](../activations.md)).\n",
      " |          If you don't specify anything, no activation is applied\n",
      " |          (ie. \"linear\" activation: `a(x) = x`).\n",
      " |      use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |      kernel_initializer: Initializer for the `kernel` weights matrix\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      bias_initializer: Initializer for the bias vector\n",
      " |          (see [initializers](../initializers.md)).\n",
      " |      kernel_regularizer: Regularizer function applied to\n",
      " |          the `kernel` weights matrix\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      bias_regularizer: Regularizer function applied to the bias vector\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      activity_regularizer: Regularizer function applied to\n",
      " |          the output of the layer (its \"activation\").\n",
      " |          (see [regularizer](../regularizers.md)).\n",
      " |      kernel_constraint: Constraint function applied to the kernel matrix\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |      bias_constraint: Constraint function applied to the bias vector\n",
      " |          (see [constraints](../constraints.md)).\n",
      " |  \n",
      " |  # Input shape\n",
      " |      4D tensor with shape:\n",
      " |      `(batch, channels, rows, cols)`\n",
      " |      if `data_format` is `\"channels_first\"`\n",
      " |      or 4D tensor with shape:\n",
      " |      `(batch, rows, cols, channels)`\n",
      " |      if `data_format` is `\"channels_last\"`.\n",
      " |  \n",
      " |  # Output shape\n",
      " |      4D tensor with shape:\n",
      " |      `(batch, filters, new_rows, new_cols)`\n",
      " |      if `data_format` is `\"channels_first\"`\n",
      " |      or 4D tensor with shape:\n",
      " |      `(batch, new_rows, new_cols, filters)`\n",
      " |      if `data_format` is `\"channels_last\"`.\n",
      " |      `rows` and `cols` values might have changed due to padding.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2D\n",
      " |      _Conv\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _Conv:\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  losses\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esousa/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n",
      "/Users/esousa/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "/Users/esousa/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/esousa/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation='relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(output_dim = 128, activation='relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation='sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esousa/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/Users/esousa/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=250, epochs=25, validation_steps=2000)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 187s 748ms/step - loss: 0.6908 - acc: 0.5330 - val_loss: 0.6717 - val_acc: 0.6261\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 182s 729ms/step - loss: 0.6558 - acc: 0.6146 - val_loss: 0.6390 - val_acc: 0.6231\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 179s 717ms/step - loss: 0.6236 - acc: 0.6554 - val_loss: 0.6018 - val_acc: 0.6789\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 176s 705ms/step - loss: 0.5921 - acc: 0.6823 - val_loss: 0.5792 - val_acc: 0.7003\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 199s 796ms/step - loss: 0.5646 - acc: 0.7110 - val_loss: 0.5468 - val_acc: 0.7306\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 196s 786ms/step - loss: 0.5288 - acc: 0.7337 - val_loss: 0.5401 - val_acc: 0.7362\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 205s 821ms/step - loss: 0.5086 - acc: 0.7509 - val_loss: 0.5294 - val_acc: 0.7495\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 211s 846ms/step - loss: 0.4930 - acc: 0.7570 - val_loss: 0.4884 - val_acc: 0.7717\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 203s 812ms/step - loss: 0.4731 - acc: 0.7751 - val_loss: 0.5204 - val_acc: 0.7528\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 198s 794ms/step - loss: 0.4471 - acc: 0.7924 - val_loss: 0.4835 - val_acc: 0.7765\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 186s 745ms/step - loss: 0.4324 - acc: 0.7945 - val_loss: 0.5141 - val_acc: 0.7581\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 184s 738ms/step - loss: 0.4096 - acc: 0.8100 - val_loss: 0.4925 - val_acc: 0.7934\n",
      "Epoch 13/25\n",
      "249/250 [============================>.] - ETA: 0s - loss: 0.3975 - acc: 0.8199"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2bc3d54edd33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                          \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                          \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                          nb_val_samples = 2000)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    235\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('/Users/esousa/transfered/Classes/udemy_machineLearning_A-Z/Part8_Deep_Learning/dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('/Users/esousa/transfered/Classes/udemy_machineLearning_A-Z/Part8_Deep_Learning/dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 25,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
